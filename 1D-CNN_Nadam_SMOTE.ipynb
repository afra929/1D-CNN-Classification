{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from pandas import set_option\n",
    "set_option(\"display.max_rows\", 10)\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from pandas import set_option\n",
    "set_option(\"display.max_rows\", 10)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense, Conv1D, MaxPool2D, Flatten, Dropout, CuDNNGRU, CuDNNLSTM, Conv2D, MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam, SGD, Nadam\n",
    "from time import time\n",
    "from livelossplot import PlotLossesKeras\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'training_data_SMOTE.csv'\n",
    "training_data = pd.read_csv(filename)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facies_counts = training_data['Facies_Type'].value_counts().sort_index()\n",
    "#use facies labels to index each count\n",
    "facies_counts.index = facies_labels\n",
    "\n",
    "facies_counts.plot(kind='bar',color=facies_colors, \n",
    "                   title='Distribution of Training Data Processed by SMOTE Algorithm by Facies')\n",
    "facies_counts\n",
    "plt.savefig('facies distribution_SMOTE.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_facies_labels = training_data['Facies_Type'].values\n",
    "\n",
    "feature_vectors = training_data.drop([ 'Well_Name','Facies_Type','FaciesLabels'], axis=1)\n",
    "\n",
    "col = list(feature_vectors.columns)\n",
    "\n",
    "feature_vectors[col] = feature_vectors[col].apply(pd.to_numeric, errors='coerce').fillna(0.0)\n",
    "\n",
    "feature_vectors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(feature_vectors)\n",
    "X_train= scaler.transform(feature_vectors)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= np.expand_dims(X_train, axis=2)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "#one-hot encode target column\n",
    "y_train = to_categorical(correct_facies_labels)\n",
    "y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train,  y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model\n",
    "model = Sequential()\n",
    "#get number of columns in training data\n",
    "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "\n",
    "#add model layers\n",
    "model.add(Conv1D(64, 2, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "model.add(Conv1D(64, 2, activation='relu'))\n",
    "model.add(MaxPooling1D(1))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(64, 1, activation='relu'))\n",
    "model.add(Conv1D(64, 1, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "#compile model using mse as a measure of model performance\n",
    "model.compile(optimizer='Nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set early stopping monitor so the model stops training when it won't improve anymore\n",
    "early_stopping_monitor = EarlyStopping(patience=500)\n",
    "\n",
    "filepath=\"models\\\\CNN_NadamSMOTE.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_mape', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#train model\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=64, validation_split=0.3,\n",
    "          verbose=1, callbacks=[PlotLossesKeras(), early_stopping_monitor, checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Evaluation on test data: loss = %0.6f accuracy = %0.2f%% \\n\" \\\n",
    "      % (eval[0], eval[1] * 100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving model to disk \\n\")\n",
    "model.save('model_Nadam_SMOTE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truelabel = y_test.argmax(axis=-1)\n",
    "truelabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "con_mat = confusion_matrix(truelabel, y_pred)\n",
    "\n",
    "con_mat_norm = con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis]   \n",
    "con_mat_norm = np.around(con_mat_norm, decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(9, 8))\n",
    "sns.heatmap(con_mat_norm, annot=True, cmap='Blues')\n",
    "\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.savefig('heatmap_Nadam_SMOTE.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
